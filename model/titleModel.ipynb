{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import os, csv\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_folder = '../dataset/'\n",
    "with open(data_folder + 'genres.txt', 'r') as f:\n",
    "    genres_list = [g.replace('\\n','') for g in f.readlines()]\n",
    "movies_train = pd.read_csv(data_folder + 'movies_train.csv')\n",
    "movies_test = pd.read_csv(data_folder + 'movies_test.csv')\n",
    "movies_val = pd.read_csv(data_folder + 'movies_val.csv')\n",
    "# movies_train, movies_val = train_test_split(movies_train, test_size=0.1, random_state=42)\n",
    "# movies_train.reset_index(drop=True, inplace=True)\n",
    "# movies_test.reset_index(drop=True, inplace=True)\n",
    "# movies_val.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_MAX_LEN = 15\n",
    "pad_token = '<PAD>'\n",
    "unk_token = '<UNK>'\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def create_vocab(dataset, column='title'):\n",
    "    df = dataset.copy()\n",
    "    titles = df[column].tolist()\n",
    "    vocab = set()\n",
    "    for title in titles:\n",
    "        tokens = tokenize(title)\n",
    "        vocab.update(tokens)\n",
    "    vocab = list(vocab)\n",
    "    vocab.append(pad_token)\n",
    "    vocab.append(unk_token)\n",
    "    return vocab\n",
    "\n",
    "def onehot_vectorize(title, title2int):\n",
    "    tokens = tokenize(title)\n",
    "    tokens = tokens[:TITLE_MAX_LEN]\n",
    "    while len(tokens) < TITLE_MAX_LEN:\n",
    "        tokens.append(pad_token)\n",
    "    title_vec = np.zeros((TITLE_MAX_LEN,len(title2int)), dtype=np.float32)\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in title2int:\n",
    "            title_vec[i][title2int[token]] = 1\n",
    "        else:\n",
    "            title_vec[i][title2int[unk_token]] = 1\n",
    "    return title_vec\n",
    "    \n",
    "def multihot_genres(genres,  genres_dict):\n",
    "    genres = genres.strip('][').replace(\"'\", \"\").split(', ')\n",
    "    multi_hot = np.zeros(len(genres_dict) + 1)\n",
    "    for genre in genres:\n",
    "        if genre in genres_dict:\n",
    "                multi_hot[genres_dict[genre]] = 1\n",
    "    multi_hot[-1] = len(genres)\n",
    "    return multi_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class titleDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        # title process\n",
    "        vocab = create_vocab(df, column='title')\n",
    "        self.vocab_size = len(vocab)\n",
    "        self.title2int = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "        # genres process\n",
    "        genres_list = ['Crime', 'Thriller', 'Fantasy', 'Horror', 'Sci-Fi', 'Comedy', 'Documentary', 'Adventure', 'Film-Noir', 'Animation', 'Romance', 'Drama', 'Western', 'Musical', 'Action', 'Mystery', 'War', \"Children's\"]\n",
    "        self.genre2int = {genre: i for i, genre in enumerate(genres_list)} \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title = self.df.iloc[idx]['title']\n",
    "        title_vec = onehot_vectorize(title, self.title2int)\n",
    "        genres = self.df.iloc[idx]['genre']\n",
    "        genres_vec = multihot_genres(genres, self.genre2int)\n",
    "        # print('*****************************')\n",
    "        # print(title)\n",
    "        # print(title_vec)\n",
    "        # print(genres)\n",
    "        # print(genres_vec)\n",
    "        # print('*****************************')\n",
    "        return title_vec, genres_vec\n",
    "    \n",
    "    def merge_vocab(self, other):\n",
    "        self.title2int.update(other.title2int)\n",
    "        self.genre2int.update(other.genre2int)\n",
    "        self.vocab_size = len(self.title2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_at_K(k, pred, truth):\n",
    "    # print(pred)\n",
    "    _, indices = torch.topk(pred, k=k)\n",
    "    correct = 0\n",
    "    for id in indices:\n",
    "        if truth[id] > 0:\n",
    "            correct += 1\n",
    "    return correct / k\n",
    "\n",
    "def AP_at_K(k, pred, truth):\n",
    "    AP = 0\n",
    "    for i in range(1, k+1):\n",
    "        AP += P_at_K(i, pred, truth) \n",
    "    return AP / k\n",
    "\n",
    "def MAP_at_K(k, pred_list, truth_list):\n",
    "    MAP = 0\n",
    "    for i in range(len(pred_list)):\n",
    "        MAP += AP_at_K(k, pred_list[i], truth_list[i])\n",
    "    return MAP / len(pred_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = titleDataset(movies_train)\n",
    "val = titleDataset(movies_val)\n",
    "test = titleDataset(movies_test)\n",
    "train.merge_vocab(val)\n",
    "train.merge_vocab(test)\n",
    "val.merge_vocab(train)\n",
    "test.merge_vocab(train)\n",
    "train_dataloader = DataLoader(train, batch_size=32, shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val, batch_size=32, shuffle=False, num_workers=6)\n",
    "test_dataloader = DataLoader(test, batch_size=32, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class titleModel(pl.LightningModule):\n",
    "    def __init__(self, core, input_size, hidden_size, num_layers=1, batch_first=True, bidirectional = False, device = 'cpu'):\n",
    "        super(titleModel,self).__init__()\n",
    "        self.dev = device # device variable was taken, so using dev instead :(\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        if core == 'RNN':\n",
    "            self.core = nn.RNN(\n",
    "                input_size = input_size, \n",
    "                hidden_size = hidden_size, \n",
    "                num_layers = num_layers, \n",
    "                batch_first = batch_first, \n",
    "                nonlinearity = 'relu', \n",
    "                bidirectional = bidirectional\n",
    "            )\n",
    "        else:\n",
    "            self.core = nn.LSTM(\n",
    "                input_size = input_size, \n",
    "                hidden_size = hidden_size, \n",
    "                num_layers = num_layers, \n",
    "                batch_first = batch_first, \n",
    "                bidirectional = bidirectional\n",
    "            )\n",
    "        linear_size = hidden_size\n",
    "        if bidirectional:\n",
    "            linear_size *= 2\n",
    "        self.linear = nn.Linear(linear_size, 18)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out, _ = self.core(x)#, h0)  \n",
    "        # out = [batch_size, seq_len, hidden_size*bidirectional (vector size)]\n",
    "        # => only take the last element (many to one RNN)\n",
    "        out = out[:, -1, :]  \n",
    "        out = self.linear(out)\n",
    "        # out = self.sigmoid(out)\n",
    "        # out = self.softmax(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        title, genres = train_batch\n",
    "        # print(\"-----------------------------------\", title.shape, genres.shape)\n",
    "        # title_tensor = torch.tensor(title).to(self.dev)\n",
    "        # genre_tensor = torch.tensor(genres).to(self.dev)\n",
    "        title_tensor = title.clone().detach().to(self.dev)\n",
    "        genre_tensor = genres.clone().detach().to(self.dev)\n",
    "\n",
    "        # print(\"***********************************\", title_tensor)\n",
    "        output = self.forward(title_tensor)\n",
    "        loss = self.cross_entropy_loss(output, genre_tensor)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        title, genres = val_batch\n",
    "        title_tensor = title.clone().detach().to(self.dev)\n",
    "        genre_tensor = genres.clone().detach().to(self.dev)\n",
    "        \n",
    "        output = self.forward(title_tensor)\n",
    "        loss = self.cross_entropy_loss(output, genre_tensor)\n",
    "        self.log('val_loss', loss)\n",
    "        # print('val_loss', loss)\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        title, genres = test_batch\n",
    "        title_tensor = title.clone().detach().to(self.dev)\n",
    "        genre_tensor = genres.clone().detach().to(self.dev)\n",
    "        \n",
    "        output = self.forward(title_tensor)\n",
    "        \n",
    "        MAP = MAP_at_K(3, output, genre_tensor)\n",
    "        print('MAP@3', MAP)\n",
    "        self.log('MAP@3', MAP)\n",
    "        return {'MAP@3': MAP}\n",
    "    \n",
    "    # def on_test_epoch_end(self, outputs):\n",
    "    #     avg_MAP = torch.stack([x['MAP@3'] for x in outputs]).mean()\n",
    "    #     print('avg_MAP@3', avg_MAP)\n",
    "    #     self.log('avg_MAP@3', avg_MAP)\n",
    "    #     return {'avg_MAP@3': avg_MAP}\n",
    "\n",
    "    def predict_step(self, test_batch, batch_idx):\n",
    "        title, genres = test_batch\n",
    "        title_tensor = title.clone().detach().to(self.dev)\n",
    "        genre_tensor = genres.clone().detach().to(self.dev)\n",
    "        \n",
    "        output = self.forward(title_tensor)\n",
    "        return output, genre_tensor\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(),lr=0.001)\n",
    "    \n",
    "    def cross_entropy_loss(self,logits,labels):\n",
    "        return F.cross_entropy(logits,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | core    | LSTM    | 4.7 M \n",
      "1 | linear  | Linear  | 4.6 K \n",
      "2 | sigmoid | Sigmoid | 0     \n",
      "3 | softmax | Softmax | 0     \n",
      "------------------------------------\n",
      "4.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 M     Total params\n",
      "18.807    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4071\n",
      "Epoch 19: 100%|██████████| 78/78 [00:02<00:00, 33.89it/s, v_num=58]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 78/78 [00:02<00:00, 31.82it/s, v_num=58]\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(train_dataloader.dataset.vocab_size)\n",
    "titleModel = titleModel(core = 'LSTM',input_size = train_dataloader.dataset.vocab_size, hidden_size = 128, num_layers=2, bidirectional= True,device = device)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=NUM_EPOCHS, num_sanity_val_steps=0)\n",
    "trainer.fit(titleModel, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huy/miniconda3/envs/ml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:186: .test(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/25 [00:00<?, ?it/s]MAP@3 0.2934027777777777\n",
      "Testing DataLoader 0:   4%|▍         | 1/25 [00:00<00:01, 13.75it/s]MAP@3 0.2864583333333332\n",
      "Testing DataLoader 0:   8%|▊         | 2/25 [00:00<00:01, 20.93it/s]MAP@3 0.3541666666666665\n",
      "Testing DataLoader 0:  12%|█▏        | 3/25 [00:00<00:01, 19.48it/s]MAP@3 0.32812499999999994\n",
      "Testing DataLoader 0:  16%|█▌        | 4/25 [00:00<00:00, 22.76it/s]MAP@3 0.2465277777777777\n",
      "Testing DataLoader 0:  20%|██        | 5/25 [00:00<00:00, 25.15it/s]MAP@3 0.2135416666666666\n",
      "Testing DataLoader 0:  24%|██▍       | 6/25 [00:00<00:00, 27.07it/s]MAP@3 0.23263888888888884\n",
      "Testing DataLoader 0:  28%|██▊       | 7/25 [00:00<00:00, 28.48it/s]MAP@3 0.29861111111111094\n",
      "Testing DataLoader 0:  32%|███▏      | 8/25 [00:00<00:00, 29.73it/s]MAP@3 0.29513888888888884\n",
      "Testing DataLoader 0:  36%|███▌      | 9/25 [00:00<00:00, 30.66it/s]MAP@3 0.1961805555555555\n",
      "Testing DataLoader 0:  40%|████      | 10/25 [00:00<00:00, 31.59it/s]MAP@3 0.22569444444444436\n",
      "Testing DataLoader 0:  44%|████▍     | 11/25 [00:00<00:00, 32.30it/s]MAP@3 0.2621527777777777\n",
      "Testing DataLoader 0:  48%|████▊     | 12/25 [00:00<00:00, 33.06it/s]MAP@3 0.36458333333333326\n",
      "Testing DataLoader 0:  52%|█████▏    | 13/25 [00:00<00:00, 33.70it/s]MAP@3 0.31944444444444436\n",
      "Testing DataLoader 0:  56%|█████▌    | 14/25 [00:00<00:00, 34.12it/s]MAP@3 0.28472222222222215\n",
      "Testing DataLoader 0:  60%|██████    | 15/25 [00:00<00:00, 34.48it/s]MAP@3 0.2899305555555555\n",
      "Testing DataLoader 0:  64%|██████▍   | 16/25 [00:00<00:00, 34.75it/s]MAP@3 0.34548611111111094\n",
      "Testing DataLoader 0:  68%|██████▊   | 17/25 [00:00<00:00, 35.04it/s]MAP@3 0.32986111111111105\n",
      "Testing DataLoader 0:  72%|███████▏  | 18/25 [00:00<00:00, 35.29it/s]MAP@3 0.40624999999999994\n",
      "Testing DataLoader 0:  76%|███████▌  | 19/25 [00:00<00:00, 35.54it/s]MAP@3 0.3229166666666666\n",
      "Testing DataLoader 0:  80%|████████  | 20/25 [00:00<00:00, 35.65it/s]MAP@3 0.3350694444444444\n",
      "Testing DataLoader 0:  84%|████████▍ | 21/25 [00:00<00:00, 35.87it/s]MAP@3 0.30034722222222215\n",
      "Testing DataLoader 0:  88%|████████▊ | 22/25 [00:00<00:00, 36.12it/s]MAP@3 0.23437499999999992\n",
      "Testing DataLoader 0:  92%|█████████▏| 23/25 [00:00<00:00, 36.42it/s]MAP@3 0.25173611111111105\n",
      "Testing DataLoader 0:  96%|█████████▌| 24/25 [00:00<00:00, 36.63it/s]MAP@3 0.31481481481481477\n",
      "Testing DataLoader 0: 100%|██████████| 25/25 [00:00<00:00, 37.32it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "          MAP@3             0.2926497757434845\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'MAP@3': 0.2926497757434845}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_path = \"../model/lightning_logs/version_39/checkpoints/epoch=0-step=78.ckpt\"\n",
    "checkpoint_path = \"last\"\n",
    "trainer.test(titleModel, dataloaders=test_dataloader, ckpt_path=checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huy/miniconda3/envs/ml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:186: .predict(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 25/25 [00:00<00:00, 71.01it/s]\n",
      "MAP@1  0.33462033462033464\n",
      "MAP@2  0.2985842985842986\n",
      "MAP@3  0.27999427999428045\n",
      "MAP@4  0.2616366366366373\n"
     ]
    }
   ],
   "source": [
    "res = trainer.predict(titleModel, dataloaders=test_dataloader, ckpt_path=\"last\")\n",
    "pred = torch.cat([ep[0] for ep in res])\n",
    "truth = torch.cat([ep[1] for ep in res])\n",
    "print('MAP@1 ', MAP_at_K(1, pred, truth))\n",
    "print('MAP@2 ', MAP_at_K(2, pred, truth))\n",
    "print('MAP@3 ', MAP_at_K(3, pred, truth))\n",
    "print('MAP@4 ', MAP_at_K(4, pred, truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pred:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.13211,  1.15558, -0.63910,  1.28267,  1.19266,  1.32292,  1.39921,\n",
      "          0.84996, -1.10016,  1.36085, -1.07900, -2.36797,  0.04489,  0.66294,\n",
      "          0.58657, -2.41772, -1.56134, -6.19012],\n",
      "        [-3.75969,  1.24626, -0.32128,  1.62122,  1.53668,  0.86352,  1.16034,\n",
      "          1.28893, -1.95686,  1.00306, -1.17818, -2.74277, -0.85065, -0.03989,\n",
      "          1.07012, -3.07357, -0.97900, -6.96506],\n",
      "        [-4.79051,  0.38106,  1.56849,  2.92475,  1.93658, -1.07158, -1.52262,\n",
      "          2.62998, -3.97206, -0.67645, -0.89711, -3.19688, -3.67912, -2.83179,\n",
      "          2.61953, -3.98802,  1.36768, -7.33003]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "F1 - micro:     0.3222317107884999\n",
      "F1 - macro:     0.12910693471953547\n",
      "F1 - weighted:  0.32536383404854907\n",
      "F1 - samples:   0.31654409511552367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huy/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/huy/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=5, sci_mode=False)\n",
    "print(pred[:3])\n",
    "pred_1 = torch.zeros(pred.shape)\n",
    "for i in range(pred.shape[0]):\n",
    "    ids = torch.topk(pred[i], k=3).indices\n",
    "    # ids = [j*(pred[i][j] > 0.5) for j in range(len(pred[i]))]\n",
    "    for id in ids:\n",
    "        pred_1[i][id] = 1\n",
    "print(pred_1[:3])\n",
    "print(truth[:3])\n",
    "print('F1 - micro:    ',f1_score(truth, pred_1, average='micro'))\n",
    "print('F1 - macro:    ',f1_score(truth, pred_1, average='macro'))\n",
    "print('F1 - weighted: ',f1_score(truth, pred_1, average='weighted'))\n",
    "print('F1 - samples:  ',f1_score(truth, pred_1, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mF1 - micro:     tensor(0.25838)\n",
      "mF1 - macro:     tensor(0.15315)\n",
      "mF1 - weighted:  tensor(0.34076)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional.classification import multilabel_f1_score \n",
    "thres=0.5\n",
    "print('mF1 - micro:    ', multilabel_f1_score(pred, truth, num_labels=18, threshold=thres, average='micro'))\n",
    "print('mF1 - macro:    ', multilabel_f1_score(pred, truth, num_labels=18, threshold=thres, average='macro'))\n",
    "print('mF1 - weighted: ', multilabel_f1_score(pred, truth, num_labels=18, threshold=thres, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mF1@1 - macro:     tensor(0.07092)\n",
      "mF1@2 - macro:     tensor(0.11685)\n",
      "mF1@3 - macro:     tensor(0.12911)\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 4):\n",
    "    pred_1 = torch.zeros(pred.shape)\n",
    "    for i in range(pred.shape[0]):\n",
    "        ids = torch.topk(pred[i], k=k).indices\n",
    "        for id in ids:\n",
    "            pred_1[i][id] = 1\n",
    "\n",
    "    print('mF1@{} - macro:    '.format(k), multilabel_f1_score(pred_1, truth, num_labels=18, threshold=thres, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
